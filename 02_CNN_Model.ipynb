{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.keras import models\n",
    "from tensorflow.contrib.keras import layers\n",
    "from tensorflow.contrib.keras import utils\n",
    "#from tensorflow.contrib.keras.layers.normalization import BatchNormalization\n",
    "#from tensorflow.contrib.keras.python.keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Training data and Training labels & Resizing into 64*64 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabarish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training image data shape (37882, 64, 64)\n",
      "training data label shape (37882, 1)\n"
     ]
    }
   ],
   "source": [
    "#set training data and training labels\n",
    "trd_list=[]\n",
    "trl_list=[]\n",
    "\n",
    "trlbl=pd.read_csv('train.txt',index_col=0,delimiter=' ',header=None)\n",
    "trlbl.columns=['label']\n",
    "\n",
    "for image_path in glob.glob(\"train-set\\*.png\"):\n",
    "    #image=im.imread(image_path)\n",
    "    imag=Image.open(image_path)\n",
    "    imag=imag.resize((64,64),Image.ANTIALIAS)    \n",
    "    trd_list.append(np.asarray(imag))\n",
    "    fname=image_path.split('\\\\')\n",
    "    trl_list.append(trlbl.get_value(fname[1],col='label'))        \n",
    "\n",
    "train_data_orig=np.asarray(trd_list)\n",
    "print(\"training image data shape\", train_data_orig.shape)\n",
    "train_label_orig=np.array(trl_list)\n",
    "train_label_orig=train_label_orig.reshape(train_label_orig.shape[0],-1)\n",
    "print(\"training data label shape\",train_label_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Validation data and Validation labels & Resizing into 64*64 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabarish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation image data shape (6262, 64, 64)\n",
      "validation data label shape (6262, 1)\n"
     ]
    }
   ],
   "source": [
    "# validation data\n",
    "vd_list=[]\n",
    "vl_list=[]\n",
    "\n",
    "vlbl=pd.read_csv('vali.txt',index_col=0,delimiter=' ',header=None)\n",
    "vlbl.columns=['label']\n",
    "\n",
    "for image_path in glob.glob(\"vali-set\\*.png\"):\n",
    "    imag=Image.open(image_path)\n",
    "    imag=imag.resize((64,64),Image.ANTIALIAS)\n",
    "    vd_list.append(np.asarray(imag))\n",
    "    fname=image_path.split('\\\\')\n",
    "    #print(fname)\n",
    "    vl_list.append(vlbl.get_value(fname[1],col='label'))\n",
    "\n",
    "vali_data_orig=np.array(vd_list)\n",
    "print(\"validation image data shape\",vali_data_orig.shape)\n",
    "vali_label_orig=np.array(vl_list)\n",
    "vali_label_orig=vali_label_orig.reshape(vali_label_orig.shape[0],-1)\n",
    "print(\"validation data label shape\",vali_label_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 6\n",
    "#train_label_orig=train_label_orig.T\n",
    "plt.imshow(train_data_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(train_label_orig[index,: ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling & converting into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (37882, 64, 64, 1)\n",
      "Y_train shape: (37882, 62)\n",
      "X_test shape: (6262, 64, 64, 1)\n",
      "Y_test shape: (6262, 62)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data_orig/255.\n",
    "vali_data = vali_data_orig/255.\n",
    "train_data=train_data.reshape(train_data.shape[0],train_data.shape[1],train_data.shape[2],-1)\n",
    "vali_data=vali_data.reshape(vali_data.shape[0],vali_data.shape[1],vali_data.shape[2],-1)\n",
    "\n",
    "train_label=utils.to_categorical(train_label_orig, 62)\n",
    "vali_label=utils.to_categorical(vali_label_orig, 62)\n",
    "\n",
    "print (\"X_train shape: \" + str(train_data.shape))\n",
    "print (\"Y_train shape: \" + str(train_label.shape))\n",
    "print (\"X_test shape: \" + str(vali_data.shape))\n",
    "print (\"Y_test shape: \" + str(vali_label.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Parameters\n",
    "\n",
    "input_shape=(64, 64, 1)\n",
    "num_classes=62\n",
    "batch_size = 128\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition \n",
    "###### Relu Activation\n",
    "###### BatchNormalization (axis=3 (along Filters))\n",
    "###### MaxPooling(size = 2x2)\n",
    "###### +\n",
    "###### Conv2D (16 Filters, kernel_size = 3*3, stride 1*1 )\n",
    "###### Relu Activation\n",
    "###### BatchNormalization (axis=3 (along Filters))\n",
    "###### MaxPooling(size = 2x2)\n",
    "###### +\n",
    "###### Conv2D (32 Filters, kernel_size = 3*3, stride 1*1 )\n",
    "###### Relu Activation\n",
    "###### BatchNormalization (axis=3 (along Filters))\n",
    "###### +\n",
    "###### Conv2D (32 Filters, kernel_size = 3*3, stride 1*1 )\n",
    "###### Relu Activation\n",
    "###### +\n",
    "###### Flatten Layer\n",
    "###### +\n",
    "###### Dense Layer(units=512)\n",
    "###### Relu Activation\n",
    "###### +\n",
    "###### Dropout(0.25)\n",
    "###### +\n",
    "###### Dense Layer(units=256)\n",
    "###### Relu Activation\n",
    "###### +\n",
    "###### Dense Layer(units=128)\n",
    "###### Relu Activation\n",
    "###### +\n",
    "###### Output Dense Layer(units=62  (same as no of classes))\n",
    "###### Softmax Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',data_format='channels_last',input_shape=input_shape))\n",
    "layers.BatchNormalization(axis=3)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "layers.BatchNormalization(axis=3)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "layers.BatchNormalization(axis=3)\n",
    "model.add(layers.Conv2D(32, (1, 1), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(units=62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 32)        1056      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 2,540,206.0\n",
      "Trainable params: 2,540,206.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "295/295 [==============================] - 185s - loss: 1.3025 - acc: 0.5928 - val_loss: 0.7701 - val_acc: 0.7440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x23552493be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using ImageGenerator\n",
    "\n",
    "#preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.contrib.keras import preprocessing\n",
    "\n",
    "gen = preprocessing.image.ImageDataGenerator(rotation_range=20, width_shift_range=0.2,height_shift_range=0.2)\n",
    "\n",
    "test_gen = preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "train_generator = gen.flow(train_data, train_label, batch_size=batch_size)\n",
    "test_generator = test_gen.flow(vali_data, vali_label, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=37882//128, epochs=50, \n",
    "                    validation_data=test_generator, validation_steps=6262//128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Mode on Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.768343505426\n",
      "Test accuracy: 0.744171191294\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(vali_data, vali_label, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test image data shape (18848, 64, 64)\n",
      "image name list shape (18848,)\n",
      "test_data shape: (18848, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read Test Data and convert into 64*64 shape \n",
    "test_data=[]\n",
    "image_name=[]\n",
    "\n",
    "for image_path in glob.glob(\"test_set\\*.png\"):\n",
    "    imag=Image.open(image_path)\n",
    "    imag=imag.resize((64,64),Image.ANTIALIAS)\n",
    "    test_data.append(np.asarray(imag))\n",
    "    fname=image_path.split('\\\\')    \n",
    "    image_name.append(fname[1])\n",
    "\n",
    "test_data_orig=np.array(test_data)\n",
    "print(\"test image data shape\",test_data_orig.shape)\n",
    "image_name_orig=np.array(image_name)\n",
    "print(\"image name list shape\",image_name_orig.shape)\n",
    "\n",
    "test_data = test_data_orig/255.\n",
    "test_data=test_data.reshape(test_data.shape[0],test_data.shape[1],test_data.shape[2],-1)\n",
    "print (\"test_data shape: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18848/18848 [==============================] - 35s    \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(test_data)\n",
    "\n",
    "predictions = list(predictions)\n",
    "actuals = list(vali_label)\n",
    "\n",
    "#sub = pd.DataFrame({'Image_name':image_name_orig,'Predictions': predictions})\n",
    "sub = pd.DataFrame([image_name_orig,predictions])\n",
    "sub=sub.T\n",
    "sub.to_csv('./test.txt', index=False,header=False,sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
